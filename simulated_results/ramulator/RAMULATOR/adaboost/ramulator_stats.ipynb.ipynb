{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Simple Ramulator Stats Extractor\n",
    "Just run: python3 extract_ramulator_stats.py\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def find_stats_file():\n",
    "    \"\"\"Find ramulator stats file in current directory\"\"\"\n",
    "    # Look for common patterns\n",
    "    patterns = ['*.txt', '*stats*', '*ramulator*']\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        files = list(Path('.').glob(pattern))\n",
    "        if files:\n",
    "            return files[0]\n",
    "    \n",
    "    # If nothing found, list all txt files\n",
    "    txt_files = list(Path('.').glob('*.txt'))\n",
    "    if txt_files:\n",
    "        return txt_files[0]\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_stats_file(filename):\n",
    "    \"\"\"Parse the ramulator stats file\"\"\"\n",
    "    metrics = {}\n",
    "    channel_data = defaultdict(dict)\n",
    "    current_metric = None\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Parse main metrics\n",
    "            match = re.match(r'^\\s*([a-zA-Z_.\\d]+)\\s+([\\d.]+)\\s+#\\s*(.*)$', line)\n",
    "            if match:\n",
    "                metric_name = match.group(1)\n",
    "                value = match.group(2)\n",
    "                description = match.group(3)\n",
    "                \n",
    "                try:\n",
    "                    value = float(value) if '.' in value else int(value)\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                metrics[metric_name] = {'value': value, 'description': description}\n",
    "                current_metric = metric_name\n",
    "            \n",
    "            # Parse channel/indexed data\n",
    "            elif current_metric:\n",
    "                match = re.match(r'^\\s*\\[(.+?)\\]\\s+([\\d.]+)', line)\n",
    "                if match:\n",
    "                    index = match.group(1)\n",
    "                    value = match.group(2)\n",
    "                    try:\n",
    "                        value = float(value) if '.' in value else int(value)\n",
    "                    except:\n",
    "                        pass\n",
    "                    channel_data[current_metric][index] = value\n",
    "    \n",
    "    return metrics, dict(channel_data)\n",
    "\n",
    "\n",
    "def calculate_stats(metrics):\n",
    "    \"\"\"Calculate key statistics\"\"\"\n",
    "    stats = {}\n",
    "    \n",
    "    # Bandwidth\n",
    "    read_bw = metrics.get('ramulator.read_bandwidth', {}).get('value', 0)\n",
    "    write_bw = metrics.get('ramulator.write_bandwidth', {}).get('value', 0)\n",
    "    max_bw = metrics.get('ramulator.maximum_internal_bandwidth', {}).get('value', 1)\n",
    "    \n",
    "    stats['read_bandwidth_Bps'] = read_bw\n",
    "    stats['write_bandwidth_Bps'] = write_bw\n",
    "    stats['total_bandwidth_Bps'] = read_bw + write_bw\n",
    "    stats['bandwidth_utilization_%'] = ((read_bw + write_bw) / max_bw * 100) if max_bw > 0 else 0\n",
    "    \n",
    "    # Latency\n",
    "    stats['read_latency_avg_cycles'] = metrics.get('ramulator.read_latency_avg', {}).get('value', 0)\n",
    "    \n",
    "    # Row buffer\n",
    "    hits = metrics.get('ramulator.row_hits', {}).get('value', 0)\n",
    "    misses = metrics.get('ramulator.row_misses', {}).get('value', 0)\n",
    "    conflicts = metrics.get('ramulator.row_conflicts', {}).get('value', 0)\n",
    "    total = hits + misses + conflicts\n",
    "    \n",
    "    stats['row_hits'] = hits\n",
    "    stats['row_misses'] = misses\n",
    "    stats['row_conflicts'] = conflicts\n",
    "    stats['row_hit_rate_%'] = (hits / total * 100) if total > 0 else 0\n",
    "    stats['row_miss_rate_%'] = (misses / total * 100) if total > 0 else 0\n",
    "    stats['row_conflict_rate_%'] = (conflicts / total * 100) if total > 0 else 0\n",
    "    \n",
    "    # Queue\n",
    "    stats['avg_queue_length'] = metrics.get('ramulator.req_queue_length_avg', {}).get('value', 0)\n",
    "    \n",
    "    # Transactions\n",
    "    stats['read_transaction_bytes'] = metrics.get('ramulator.read_transaction_bytes', {}).get('value', 0)\n",
    "    stats['write_transaction_bytes'] = metrics.get('ramulator.write_transaction_bytes', {}).get('value', 0)\n",
    "    stats['total_read_requests'] = metrics.get('ramulator.incoming_read_reqs_per_channel', {}).get('value', 0)\n",
    "    \n",
    "    return stats\n",
    "\n",
    "\n",
    "def print_summary(stats):\n",
    "    \"\"\"Print nice summary\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"RAMULATOR STATISTICS SUMMARY\".center(70))\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    print(\"\\nğŸ“Š BANDWIDTH\")\n",
    "    print(f\"  Read:          {stats['read_bandwidth_Bps']:>15,} B/s ({stats['read_bandwidth_Bps']/1e9:.4f} GB/s)\")\n",
    "    print(f\"  Write:         {stats['write_bandwidth_Bps']:>15,} B/s ({stats['write_bandwidth_Bps']/1e9:.4f} GB/s)\")\n",
    "    print(f\"  Total:         {stats['total_bandwidth_Bps']:>15,} B/s ({stats['total_bandwidth_Bps']/1e9:.4f} GB/s)\")\n",
    "    print(f\"  Utilization:   {stats['bandwidth_utilization_%']:>15.4f} %\")\n",
    "    \n",
    "    print(\"\\nâš¡ LATENCY\")\n",
    "    print(f\"  Avg Read:      {stats['read_latency_avg_cycles']:>15.2f} cycles\")\n",
    "    \n",
    "    print(\"\\nğŸ’¾ ROW BUFFER\")\n",
    "    print(f\"  Hits:          {stats['row_hits']:>15,} ({stats['row_hit_rate_%']:.2f}%)\")\n",
    "    print(f\"  Misses:        {stats['row_misses']:>15,} ({stats['row_miss_rate_%']:.2f}%)\")\n",
    "    print(f\"  Conflicts:     {stats['row_conflicts']:>15,} ({stats['row_conflict_rate_%']:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nğŸ“ˆ TRANSACTIONS\")\n",
    "    print(f\"  Read Bytes:    {stats['read_transaction_bytes']:>15,}\")\n",
    "    print(f\"  Write Bytes:   {stats['write_transaction_bytes']:>15,}\")\n",
    "    print(f\"  Read Requests: {stats['total_read_requests']:>15,}\")\n",
    "    \n",
    "    print(\"\\nğŸ“¦ QUEUE\")\n",
    "    print(f\"  Avg Length:    {stats['avg_queue_length']:>15.6f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"ğŸ” Looking for stats file...\")\n",
    "    \n",
    "    # Find stats file\n",
    "    stats_file = find_stats_file()\n",
    "    if not stats_file:\n",
    "        print(\"âŒ No stats file found in current directory!\")\n",
    "        print(\"   Place your stats.txt file here and run again.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ“ Found: {stats_file}\")\n",
    "    \n",
    "    # Parse\n",
    "    print(f\"ğŸ“– Parsing {stats_file}...\")\n",
    "    metrics, channel_data = parse_stats_file(stats_file)\n",
    "    print(f\"âœ“ Parsed {len(metrics)} metrics\")\n",
    "    \n",
    "    # Calculate stats\n",
    "    stats = calculate_stats(metrics)\n",
    "    \n",
    "    # Print summary\n",
    "    print_summary(stats)\n",
    "    \n",
    "    # Save outputs\n",
    "    base_name = stats_file.stem\n",
    "    \n",
    "    # Save JSON\n",
    "    json_file = f\"{base_name}_summary.json\"\n",
    "    output_data = {\n",
    "        'summary_stats': stats,\n",
    "        'all_metrics': {k: v['value'] for k, v in metrics.items()},\n",
    "        'channel_distribution': channel_data\n",
    "    }\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    print(f\"ğŸ’¾ Saved: {json_file}\")\n",
    "    \n",
    "    # Save CSV (key metrics only)\n",
    "    csv_file = f\"{base_name}_summary.csv\"\n",
    "    with open(csv_file, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Metric', 'Value'])\n",
    "        for key, value in stats.items():\n",
    "            writer.writerow([key, value])\n",
    "    print(f\"ğŸ’¾ Saved: {csv_file}\")\n",
    "    \n",
    "    # Save detailed CSV\n",
    "    csv_detailed = f\"{base_name}_detailed.csv\"\n",
    "    with open(csv_detailed, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Metric', 'Value', 'Description'])\n",
    "        for metric_name, data in sorted(metrics.items()):\n",
    "            writer.writerow([metric_name, data['value'], data.get('description', '')])\n",
    "    print(f\"ğŸ’¾ Saved: {csv_detailed}\")\n",
    "    \n",
    "    print(\"\\nâœ… Done! Check the generated files.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
